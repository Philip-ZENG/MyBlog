---
title: "Open Source of Twetter's Recommendation Algorithm"
date: 2023-4-2
---

### Open Source of Twetter's Recommendation Algorithm

另外前两天有一个很有意思的事情，Twitter开源了他们的tweet推荐算法，推特官方的说法是“The goal of our open source endeavor is to provide full transparency to you, our users, about how our systems work”。但还是感觉很神奇，感觉这种东西一般不都是“核心科技\商业机密”嘛（不知道马斯克是怎么想的，而且之前特斯拉的车好像也把设计开源了）？另一种可能是，他们开源的是“老版本”的算法，新的已经开发完成了，所以老版本的放出来也没关系...

或者是twitter认为他们的推荐算法并不是其“核心竞争力”，因为一旦开源，所有人都可以省去研发成本，快速模仿复制，在一般常识看来，这无疑是在“自废武功”和培养潜在竞争对手，但这个行为本身对于整个开发者社区来说无疑是非常利好的。大家就有了经过真实生产实践检验的实用案例，而不是“实验室里的模型”用来学习。

说到开源/互联网资源开放程度的问题，我又想到了关于大型语言模型（类ChatGPT模型）的训练的问题。因为大型机器学习的模型的训练需要大量的数据作为“训练材料”，高质量数据的多少以及是否容易获得对于模型训练成果是非常重要的。英文互联网的高质量内容主要存在于博客和大量资料网站上，这些网站大多是可以允许开放爬取内容的，因而英文大语言模型训练数据的获取相对方便。但中文互联网现在比较高质量的文字内容基本已经不在“开放网络”上了，除了知乎，其他的论坛\博客网站基本都不行了（垃圾内容居多；垃圾数据训练出来的模型也是会输出垃圾回答）。而且相当一部分比较高质量的数据一般都在封闭平台上（微信公众号、视频网站、手机程序），不允许“自由爬取数据”，并且有相当大的成分是以视频的方式存在的，所以目前也给中文大语言模型的训练增加了难度。

在移动端（手机、平板）主导目前国内互联网市场的情况下，国内互联网的生态更倾向于“封闭”，大平台之间的互相倾轧，比如说微信之前好像就不允许直接链接到京东、淘宝的店铺，希望把用户“固定在自己的生态中”。这个在某种程度上其实是违背了互联网“开放”的初衷的。
